{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05a5461c-1fd9-4194-8637-6fbcfbd5dc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fusi√≥n TVIVIENDA + THOGAR exitosa.\n",
      "‚úÖ Fusi√≥n THOGAR + TSDEM exitosa.\n",
      "‚úÖ Fusi√≥n TSDEM + TMODULO exitosa.\n",
      "‚úÖ Filtrado por informante (`LLAVEMOD == LLAVESDE`) exitoso.\n",
      "‚úÖ Proceso completado. Archivo guardado en üìÇ C:\\Users\\LLUUI\\Desktop\\Tesis\\Datos\\ensafi_2023_bd_csv\\Merged_ENSAFI_PorInformante.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# üìÇ Ruta donde est√°n tus archivos\n",
    "base_path = r\"C:\\Users\\LLUUI\\Desktop\\Tesis\\Datos\\ensafi_2023_bd_csv\"\n",
    "\n",
    "# üìÇ Definir rutas\n",
    "files = {\n",
    "    \"TVIVIENDA\": os.path.join(base_path, \"TVIVIENDA.csv\"),\n",
    "    \"THOGAR\": os.path.join(base_path, \"THOGAR.csv\"),\n",
    "    \"TSDEM\": os.path.join(base_path, \"TSDEM.csv\"),\n",
    "    \"TMODULO\": os.path.join(base_path, \"TMODULO.csv\")\n",
    "}\n",
    "\n",
    "# üì• Cargar datos y limpiar nombres de columnas\n",
    "data = {}\n",
    "for name, path in files.items():\n",
    "    df = pd.read_csv(path, encoding='utf-8-sig')  # üî• Cargar y eliminar BOM autom√°ticamente\n",
    "    df.columns = [col.replace('\\ufeff', '').strip() for col in df.columns]  # üîß Limpiar nombres\n",
    "    data[name] = df  # Guardar DataFrame limpio\n",
    "\n",
    "# ‚úÖ Fusionar paso a paso con herencia\n",
    "if \"LLAVEVIV\" in data[\"TVIVIENDA\"].columns and \"LLAVEVIV\" in data[\"THOGAR\"].columns:\n",
    "    merged_df = data[\"TVIVIENDA\"].merge(data[\"THOGAR\"], on=\"LLAVEVIV\", how=\"left\")\n",
    "    print(\"‚úÖ Fusi√≥n TVIVIENDA + THOGAR exitosa.\")\n",
    "else:\n",
    "    print(\"üö® Error: 'LLAVEVIV' no est√° en uno de los archivos.\")\n",
    "\n",
    "if \"LLAVEHOG\" in merged_df.columns and \"LLAVEHOG\" in data[\"TSDEM\"].columns:\n",
    "    merged_df = merged_df.merge(data[\"TSDEM\"], on=[\"LLAVEVIV\", \"LLAVEHOG\"], how=\"left\")\n",
    "    print(\"‚úÖ Fusi√≥n THOGAR + TSDEM exitosa.\")\n",
    "else:\n",
    "    print(\"üö® Error: 'LLAVEHOG' no est√° en uno de los archivos.\")\n",
    "\n",
    "if \"LLAVEHOG\" in merged_df.columns and \"LLAVEHOG\" in data[\"TMODULO\"].columns:\n",
    "    merged_df = merged_df.merge(data[\"TMODULO\"], on=[\"LLAVEVIV\", \"LLAVEHOG\"], how=\"left\", suffixes=('', '_TMODULO'))\n",
    "    print(\"‚úÖ Fusi√≥n TSDEM + TMODULO exitosa.\")\n",
    "else:\n",
    "    print(\"üö® Error: 'LLAVEHOG' no est√° en uno de los archivos.\")\n",
    "\n",
    "# üîç üî• FILTRAR SOLO DONDE `LLAVEMOD == LLAVESDE`\n",
    "if \"LLAVEMOD\" in merged_df.columns and \"LLAVESDE\" in merged_df.columns:\n",
    "    merged_df = merged_df[merged_df[\"LLAVEMOD\"] == merged_df[\"LLAVESDE\"]]\n",
    "    print(\"‚úÖ Filtrado por informante (`LLAVEMOD == LLAVESDE`) exitoso.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se encontr√≥ `LLAVEMOD` o `LLAVESDE`, revisa los nombres.\")\n",
    "\n",
    "# üíæ Guardar resultados\n",
    "output_path_csv = os.path.join(base_path, \"Merged_ENSAFI_PorInformante.csv\")\n",
    "merged_df.to_csv(output_path_csv, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"‚úÖ Proceso completado. Archivo guardado en üìÇ {output_path_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e76d021a-b97e-429a-80c6-d61167c78305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CSV reordenado correctamente y guardado en:\n",
      "üìÑ C:\\Users\\LLUUI\\Desktop\\Tesis\\Datos\\ensafi_2023_bd_csv\\Merged_ENSAFI_Porinformante_ORDEN_PERSONALIZADO.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "archivo_corregido_csv = os.path.join(base_path, \"Merged_ENSAFI_Porinformante.csv\")\n",
    "\n",
    "# üì• Cargar el CSV\n",
    "df = pd.read_csv(archivo_corregido_csv, encoding=\"utf-8\")\n",
    "\n",
    "# üìú Tu lista de columnas en el orden exacto que deseas (de la imagen)\n",
    "preguntas_ordenadas = [\n",
    "    \"P1_1\", \"P1_2\", \"P1_3\", \n",
    "    \"P1_4_01\", \"P1_4_02\", \"P1_4_03\", \"P1_4_04\", \"P1_4_05\", \"P1_4_06\", \"P1_4_07\", \"P1_4_08\", \"P1_4_09\", \"P1_4_10\", \n",
    "    \"P1_5\", \"P1_6\", \"P1_7\", \"P1_8_1\", \"P1_8_2\", \"P1_8_3\", \"P1_8_4\", \"P1_8_5\", \"P1_9\", \"P1_10\",\n",
    "    \"P2_1\", \"P2_2\", \"P2_3\",\n",
    "    \"P3_6_1\", \"P3_6_2\", \"P3_6_3\", \"P3_7\", \"P3_9\", \"P3_10\",\n",
    "    \"P4_1_1\", \"P4_1_2\", \"P4_1_3\", \"P4_1_4\", \"P4_1_5\", \"P4_1_6\", \"P4_1_7\", \"P4_1_8\", \"P4_1_9\", \"P4_2\", \"P4_3\", \n",
    "    \"FILTRO_S4_1\", \"P4_4_1\", \"P4_4_2\", \"P4_5_1\", \"P4_5_2\", \"P4_5_3\", \"P4_5_4\", \"P4_6_1\", \"P4_6_2\", \"P4_6_3\", \"P4_6_4\", \"P4_6_5\",\n",
    "    \"P4_7_1\", \"P4_8_1\", \"P4_7_2\", \"P4_8_2\", \"P4_7_3\", \"P4_8_3\", \"P4_7_4\", \"P4_8_4\", \"P4_9_1\", \"P4_9_2\", \"P4_9_3\", \"P4_9_4\",\n",
    "    \"P4_9_5\", \"P4_9_6\", \"P4_10_1\", \"P4_10_2\", \"P4_10_3\", \"P4_10_4\", \"P4_10_5\", \"P4_10_6\",\n",
    "    \"FILTRO_S5_1\", \"P5_1\", \"P5_2_1\", \"P5_2_2\", \"P5_2_3\", \"P5_2_4\", \"P5_2_5\", \"P5_2_6\", \"P5_2_7\", \"P5_2_8\",\n",
    "    \"P5_3\", \"P5_4\", \"P5_4A\", \"P5_5\", \"P5_6\", \"P5_7\", \"P5_8\", \"P5_9_1\", \"P5_9_2\", \"P5_10_1\", \"P5_10_2\", \"P5_11\",\n",
    "    \"FILTRO_S5_2\", \"P5_12\", \"FILTRO_S5_3\", \"P5_13\", \"P5_14\", \"P5_15\", \"P5_16\", \"P5_17\", \"P5_18_1\", \"P5_18_2\",\n",
    "    \"P5_18_3\", \"P5_18_4\", \"P5_18_5\", \"P5_18_6\", \"P5_18_7\", \"P5_19\", \"P5_19A\", \"P5_20\", \"FILTRO_S5_3_1\", \"P5_21\",\n",
    "    \"P5_22\", \"FILTRO_S5_4\", \"P5_23_1\", \"P5_23_2\", \"P5_23_3\", \"P5_23_4\", \"P5_23_5\", \"P5_23_6\", \"P5_23_7\", \"P5_23_8\", \"P5_23_9\",\n",
    "    \"P6_1_1\", \"P6_1_2\", \"P6_1_3\", \"P6_1_4\", \"P6_1_5\", \"P6_1_6\", \"P6_2_01\", \"P6_2_02\", \"P6_2_03\", \"P6_2_04\",\n",
    "    \"P6_2_05\", \"P6_2_06\", \"P6_2_07\", \"P6_2_08\", \"P6_2_09\", \"P6_2_10\", \"P6_3\", \"FILTRO_S6_1\", \"P6_4\", \"P6_5_1\",\n",
    "    \"P6_5_2\", \"P6_5_3\", \"P6_5_4\", \"P6_5_5\", \"P6_6_1\", \"P6_6_2\", \"P6_6_3\", \"P6_6_4\", \"P6_6_5\", \"P6_6_6\", \"P6_6_7\", \"P6_6_8\", \"P6_6_9\",\n",
    "    \"FILTRO_S6_2\", \"P6_7\", \"P6_8\", \"P6_9\", \"P6_10_1\", \"P6_10_2\", \"P6_10_3\", \"P6_10_4\", \"P6_10_5\", \"P6_10_6\",\n",
    "    \"P6_10_7\", \"P6_10_8\", \"P6_11_1\", \"P6_11_2\", \"P6_11_3\", \"P6_11_4\", \"P6_11_5\", \"P6_12\", \"P6_13\",\n",
    "    \"P7_1\", \"P7_2_1\", \"P7_2_2\", \"P7_2_3\", \"P7_2_4\", \"P7_3\", \"P7_4\", \"P7_5_1\", \"P7_5_2\", \"P7_5_3\", \"P7_5_4\", \"P7_5_5\", \"P7_5_6\",\n",
    "    \"P7_6_1\", \"P7_6_2\", \"P7_6_3\", \"P7_6_4\", \"P7_6_5\", \"P7_6_6\", \"P7_6_7\", \"P7_6_8\", \"P7_7_1\", \"P7_7_2\", \"P7_7_3\", \"P7_7_4\", \"P7_7_5\", \"P7_7_6\",\n",
    "    \"P7_8_1\", \"P7_8_2\", \"P7_8_3\", \"P7_8_4\", \"P7_8_5\", \"P7_8_6\", \"P7_9_1\", \"P7_9_2\", \"P7_9_3\", \"P7_10_01\",\n",
    "    \"P7_10_02\", \"P7_10_03\", \"P7_10_04\", \"P7_10_05\", \"P7_10_06\", \"P7_10_07\", \"P7_10_08\", \"P7_10_09\", \"P7_10_10\", \"P7_10_11\", \"P7_10_12\",\n",
    "    \"P7_11_1\", \"P7_11_2\", \"P7_11_3\", \"P7_11_4\", \"P7_12_1\", \"P7_12_2\", \"P7_12_3\", \"P7_12_4\", \"P7_12_5\", \"P7_12_6\",\n",
    "    \"P8_1_1\", \"P8_1_2\", \"P8_1_3\", \"P8_1_4\", \"P8_1_5\", \"P8_1_6\", \"P8_2_1\", \"P8_2_2\", \"P8_2_3\", \"P8_2_4\",\n",
    "    \"P8_3_01\", \"P8_3_02\", \"P8_3_03\", \"P8_3_04\", \"P8_3_05\", \"P8_3_06\", \"P8_3_07\", \"P8_3_08\", \"P8_3_09\", \"P8_3_10\",\n",
    "    \"P8_4\", \"P8_5_1\", \"P8_5_2\", \"P8_5_3\", \"P8_5_4\", \"P8_5_5\", \"P8_5_6\", \"P8_5_7\", \"P8_5_8\", \"P8_5_9\",\n",
    "    \"P8_6_01\", \"P8_6_02\", \"P8_6_03\", \"P8_6_04\", \"P8_6_05\", \"P8_6_06\", \"P8_6_07\", \"P8_6_08\", \"P8_6_09\", \"P8_6_10\", \"P8_6_11\",\n",
    "    \"P9_1\", \"P9_2\", \"P9_3_1\", \"P9_3_2\", \"P9_3_3\", \"P9_3_4\", \"P9_3_5\", \"P9_3_6\", \"P9_3_7\",\n",
    "    \"P10_1\", \"P10_2\", \"P10_3\", \"P10_4_1\", \"P10_4_2\", \"P10_4_3\", \"P10_4_4\", \"P10_4_5\", \"P10_4_6\"\n",
    "]\n",
    "\n",
    "\n",
    "# üîÑ Detectar las que S√ç est√°n en el DataFrame (puede que algunas falten)\n",
    "preguntas_encontradas = [col for col in preguntas_ordenadas if col in df.columns]\n",
    "otras_columnas = [col for col in df.columns if col not in preguntas_encontradas]\n",
    "\n",
    "# üìå Ordenar\n",
    "nuevo_orden = preguntas_encontradas + otras_columnas\n",
    "\n",
    "# üóÇÔ∏è Reordenar el DataFrame\n",
    "df_reordenado = df[nuevo_orden]\n",
    "\n",
    "# üíæ Guardar el nuevo CSV\n",
    "output_path_csv = os.path.join(base_path, \"Merged_ENSAFI_Porinformante_ORDEN_PERSONALIZADO.csv\")\n",
    "df_reordenado.to_csv(output_path_csv, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"‚úÖ CSV reordenado correctamente y guardado en:\\nüìÑ {output_path_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e399f42-b4d9-4f67-a6c7-f96133ffb449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Columnas duplicadas eliminadas correctamente.\n",
      "‚úÖ Proceso completado. Archivo guardado en üìÇ C:\\Users\\LLUUI\\Desktop\\Tesis\\Datos\\ensafi_2023_bd_csv\\Merged_ENSAFI_ColumnasFinal.csv\n"
     ]
    }
   ],
   "source": [
    "df = df_reordenado\n",
    "\n",
    "# üîç 1Ô∏è‚É£ Encontrar la columna donde empieza LLAVEVIV\n",
    "col_inicio_revisar = df.columns.get_loc(\"LLAVEVIV\")  # Encuentra su posici√≥n\n",
    "\n",
    "# üîç 2Ô∏è‚É£ Separar en dos partes: primeras columnas y columnas a revisar\n",
    "df_fijo = df.iloc[:, :col_inicio_revisar]  # üìå Mantener las primeras columnas ordenadas (P_x_x)\n",
    "df_revisar = df.iloc[:, col_inicio_revisar:]  # üîç Revisar solo a partir de LLAVEVIV\n",
    "\n",
    "# üóëÔ∏è 3Ô∏è‚É£ Eliminar las llaves innecesarias\n",
    "llaves_a_eliminar = [\"LLAVEVIV\", \"LLAVEHOG\", \"LLAVESDE\", \"LLAVEMOD\"]  # Llaves a eliminar\n",
    "df_revisar = df_revisar.drop(columns=[col for col in llaves_a_eliminar if col in df_revisar.columns])\n",
    "\n",
    "# üî• 4Ô∏è‚É£ Eliminar columnas completamente duplicadas en `df_revisar`\n",
    "df_revisar = df_revisar.loc[:, ~df_revisar.T.duplicated()]\n",
    "\n",
    "print(\"‚úÖ Columnas duplicadas eliminadas correctamente.\")\n",
    "\n",
    "# üîÑ 5Ô∏è‚É£ Volver a unir el dataset con las primeras columnas intactas\n",
    "df_final = pd.concat([df_fijo, df_revisar], axis=1)\n",
    "\n",
    "# üíæ Guardar el dataset limpio\n",
    "output_path_csv = os.path.join(base_path, \"Merged_ENSAFI_ColumnasFinal.csv\")\n",
    "df_final.to_csv(output_path_csv, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"‚úÖ Proceso completado. Archivo guardado en üìÇ {output_path_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56ddcb80-a303-4d2b-b554-b6d6ff202722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo con variables usadas guardado en: C:\\Users\\LLUUI\\Desktop\\Tesis\\Datos\\ensafi_2023_bd_csv\\variables_usadas_2.csv\n",
      "‚úÖ Archivo con variables restantes guardado en: C:\\Users\\LLUUI\\Desktop\\Tesis\\Datos\\ensafi_2023_bd_csv\\variables_restantes.csv\n",
      "\n",
      "Total de variables usadas: 109\n",
      "Total de variables restantes: 224\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "base_path = r\"C:\\Users\\LLUUI\\Desktop\\Tesis\\Datos\\ensafi_2023_bd_csv\"\n",
    "output_path_csv = os.path.join(base_path, \"Merged_ENSAFI_ColumnasFinal.csv\")\n",
    "df = pd.read_csv(output_path_csv, encoding=\"utf-8\")\n",
    "\n",
    "# 1) Limpiar nombres de columnas por si hay espacios o caracteres ocultos\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "vars_formal = [\n",
    "  # Secciom 6.1\n",
    "  \"P6_1_2\",\n",
    "  # Secci√≥n 6.2\n",
    "  \"P6_2_01\", \"P6_2_02\", \"P6_2_03\", \"P6_2_04\", \"P6_2_05\", \n",
    "  \"P6_2_06\", \"P6_2_07\", \"P6_2_08\", \"P6_2_09\", \"P6_2_10\", \n",
    "  # Cuentas y seguros formales\n",
    "  \n",
    "  # Secci√≥n 6.6\n",
    "  \"P6_6_1\", \"P6_6_2\", \"P6_6_3\", \"P6_6_8\" \n",
    "  # Tarjeta de cr√©dito dept, cr√©dito bancario, n√≥mina, apps de pr√©stamo\n",
    "]\n",
    "\n",
    "# INSTRUMENTOS INFORMALES\n",
    "vars_informal = [\n",
    "  # Secci√≥n 6.1\n",
    "  \"P6_1_1\",\"P6_1_3\", \"P6_1_4\", \"P6_1_5\", \"P6_1_6\",  # USTED Caja de ahorro del trabajo, familiares, tanda, casa\n",
    "  \n",
    "  # Secci√≥n 6.5\n",
    "  \"P6_5_1\", \"P6_5_2\", \"P6_5_3\", \"P6_5_4\"   # USTED Deuda en caja de ahorro, empe√±o, amistades, familiares\n",
    "]\n",
    "\n",
    "# √çNDICE DE SALUD FINANCIERA (ISF)\n",
    "vars_isf =[\n",
    "  # 1. Ingresos/Gastos\n",
    "  \"P4_10_1\", \"P4_10_2\", \"P4_10_4\",\n",
    "  \n",
    "  # 2. Ahorro/Resiliencia\n",
    "  \"P7_6_1\", \"P6_3\", \"P7_6_3\", \"P7_6_4\",\n",
    "  \n",
    "  # 3. Endeudamiento\n",
    "  \"P6_7\", \"P6_8\", \"P6_10_7\", \"P4_8_1\",\n",
    "  \n",
    "  # 4. Planificaci√≥n\n",
    "  \"P7_1\", \"P7_2_1\", \"P7_2_2\", \"P7_2_3\", \"P7_2_4\", \"P7_3\", \"P7_4\",\n",
    "  \n",
    "  # 5. Percepci√≥n/Bienestar\n",
    "  \"P8_4\", \"P8_1_2\", \"P8_1_3\", \"P8_2_1\",\n",
    "  \"P8_3_01\", \"P8_3_04\"\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# CONTROLES\n",
    "# =============================================================================\n",
    "# Variables que no son instrumentos ni parte del ISF, pero sirven para ajustar (PSM, regresiones).\n",
    "vars_controls = [\n",
    "    # Secci√≥n 1\n",
    "    \"P1_1\", \"P1_2\", \"P1_3\", \n",
    "    \"P1_4_01\",\"P1_4_02\",\"P1_4_03\",\"P1_4_04\",\"P1_4_05\",\n",
    "    \"P1_4_06\",\"P1_4_07\",\"P1_4_08\",\"P1_4_09\",\"P1_4_10\",\n",
    "    \"P1_5\",\n",
    "    \n",
    "    # Secci√≥n 2\n",
    "    \"P2_1\",\"P2_2\",\n",
    "\n",
    "    # Secci√≥n 4\n",
    "    # (Fuentes de ingreso excepto P4_1_7, que es formal)\n",
    "    # \"P4_1_1\",\"P4_1_2\",\"P4_1_3\",\"P4_1_4\",\"P4_1_5\",\"P4_1_6\",\"P4_1_8\",\"P4_1_9\",\n",
    "    \"P4_2\",\n",
    "\n",
    "    # Secci√≥n 5\n",
    "    \"P5_2_1\", \"P5_2_2\", \"P5_2_3\", \"P5_2_4\",\n",
    "    \"P5_2_5\", \"P5_2_6\", \"P5_2_7\", \"P5_2_8\",\n",
    "    \"P5_3\",\"P5_5\",\"P5_7\",\"P5_11\",\"P5_21\",\n",
    "\n",
    "    # Variables derivadas o de dise√±o muestral (si existen en tu DF):\n",
    "    \"REGION_x\", \n",
    "    # Demogr√°ficas/psicol√≥gicas si existen:\n",
    "    \"PAREN\", \"SEXO\", \"EDAD\", \"NIV\", \"GRA\",\n",
    "    \"NIV_BIENES\", \n",
    "    #\"INGRESO_M\", \n",
    "    \"NIV_ESTRES\", \"SALARIO_ENT\",\n",
    "    \"DEPEN_SUM\", \"DEP_ECO\", \"FAC_ELE\"\n",
    "]\n",
    "vars_psi = [\n",
    "    \"P7_10_01\", \"P7_10_02\", \"P7_10_03\", \"P7_10_04\", \n",
    "    \"P7_10_05\", \"P7_10_06\", \"P7_10_07\", \"P7_10_08\",\n",
    "    \"P7_10_09\", \"P7_10_10\", \"P7_10_11\", \"P7_10_12\",\n",
    "    \"P7_11_1\", \"P7_11_2\", \"P7_11_3\", \"P7_11_4\",\n",
    "    \"P7_12_1\", \"P7_12_2\", \"P7_12_3\"\n",
    "]\n",
    "\n",
    "# üîÑ 3Ô∏è‚É£ Verificar qu√© variables est√°n realmente en el dataset\n",
    "all_vars = vars_formal + vars_informal + vars_isf + vars_controls + vars_psi\n",
    "all_vars = [var for var in all_vars if var in df.columns]  # Filtrar las que existen en df\n",
    "\n",
    "# üîç 4Ô∏è‚É£ Dividir el dataset\n",
    "df_used = df[all_vars]  # Solo variables usadas\n",
    "df_others = df.drop(columns=all_vars)  # Resto de variables\n",
    "\n",
    "# üíæ 5Ô∏è‚É£ Guardar en archivos CSV\n",
    "output_path_csv1 = os.path.join(base_path, \"variables_usadas_2.csv\")\n",
    "output_path_csv2 = os.path.join(base_path, \"variables_restantes.csv\")\n",
    "\n",
    "df_used.to_csv(output_path_csv1, index=False, encoding='utf-8')\n",
    "df_others.to_csv(output_path_csv2, index=False, encoding='utf-8')\n",
    "\n",
    "# üì¢ 6Ô∏è‚É£ Mensajes de confirmaci√≥n\n",
    "print(\"‚úÖ Archivo con variables usadas guardado en:\", output_path_csv1)\n",
    "print(\"‚úÖ Archivo con variables restantes guardado en:\", output_path_csv2)\n",
    "print(\"\\nTotal de variables usadas:\", len(df_used.columns))\n",
    "print(\"Total de variables restantes:\", len(df_others.columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342bc14f-7777-4306-b67c-11a0c26a648b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
